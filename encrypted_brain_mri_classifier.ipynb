{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# For encryption\n",
    "from cryptography.fernet import Fernet\n",
    "import io\n",
    "\n",
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set paths\n",
    "train_dir = '/content/drive/MyDrive/mini_proj/Training'\n",
    "test_dir = '/content/drive/MyDrive/mini_proj/Testing'\n",
    "\n",
    "# Define parameters\n",
    "IMG_SIZE = 150  # Reduced from 224 to save memory\n",
    "BATCH_SIZE = 16  # Reduced from 32 to save memory\n",
    "EPOCHS = 20  # Reduced from 30\n",
    "NUM_CLASSES = 4  # glioma, meningioma, notumor, pituitary\n",
    "\n",
    "# Generate encryption key\n",
    "key = Fernet.generate_key()\n",
    "cipher_suite = Fernet(key)\n",
    "\n",
    "# Modified encryption/decryption to process in batches\n",
    "def process_in_batches(directory, process_func, batch_size=100):\n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "    class_names = sorted(os.listdir(directory))\n",
    "\n",
    "    for class_idx, class_name in enumerate(class_names):\n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "        image_files = os.listdir(class_dir)\n",
    "\n",
    "        # Process in batches to save memory\n",
    "        for i in range(0, len(image_files), batch_size):\n",
    "            batch_files = image_files[i:i+batch_size]\n",
    "            batch_data = []\n",
    "\n",
    "            for img_name in batch_files:\n",
    "                img_path = os.path.join(class_dir, img_name)\n",
    "                processed_data = process_func(img_path)\n",
    "                batch_data.append(processed_data)\n",
    "\n",
    "            all_data.extend(batch_data)\n",
    "            all_labels.extend([class_name] * len(batch_data))\n",
    "\n",
    "    return all_data, all_labels, class_names\n",
    "\n",
    "# Encryption function\n",
    "def encrypt_image(image_path):\n",
    "    with open(image_path, 'rb') as f:\n",
    "        image_data = f.read()\n",
    "    encrypted_data = cipher_suite.encrypt(image_data)\n",
    "    return encrypted_data\n",
    "\n",
    "# Decryption function\n",
    "def decrypt_image(encrypted_data):\n",
    "    decrypted_data = cipher_suite.decrypt(encrypted_data)\n",
    "    image = Image.open(io.BytesIO(decrypted_data))\n",
    "    return image\n",
    "\n",
    "# Process dataset in memory-efficient way\n",
    "print(\"Processing training data in batches...\")\n",
    "train_encrypted, train_labels, class_names = process_in_batches(train_dir, encrypt_image)\n",
    "print(\"Processing testing data in batches...\")\n",
    "test_encrypted, test_labels, _ = process_in_batches(test_dir, encrypt_image)\n",
    "\n",
    "# Memory-efficient generator for decrypted images\n",
    "class DecryptedImageGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, encrypted_images, labels, batch_size, img_size, num_classes, shuffle=True):\n",
    "        self.encrypted_images = encrypted_images\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.num_classes = num_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.label_to_num = {class_name:i for i, class_name in enumerate(sorted(set(labels)))}\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.encrypted_images) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        batch_encrypted = [self.encrypted_images[i] for i in batch_indices]\n",
    "        batch_labels = [self.labels[i] for i in batch_indices]\n",
    "\n",
    "        X = np.zeros((len(batch_encrypted), self.img_size, self.img_size, 3), dtype=np.float32)\n",
    "        y = np.zeros((len(batch_encrypted), self.num_classes), dtype=np.float32)\n",
    "\n",
    "        for i, (encrypted_img, label) in enumerate(zip(batch_encrypted, batch_labels)):\n",
    "            # Decrypt and process image\n",
    "            img = decrypt_image(encrypted_img)\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "            img = img.resize((self.img_size, self.img_size))\n",
    "            img_array = np.array(img) / 255.0\n",
    "            X[i] = img_array\n",
    "\n",
    "            # Process label\n",
    "            y[i, self.label_to_num[label]] = 1\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indices = np.arange(len(self.encrypted_images))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "# Create generators\n",
    "train_generator = DecryptedImageGenerator(\n",
    "    train_encrypted, train_labels,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    img_size=IMG_SIZE,\n",
    "    num_classes=NUM_CLASSES\n",
    ")\n",
    "\n",
    "test_generator = DecryptedImageGenerator(\n",
    "    test_encrypted, test_labels,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    img_size=IMG_SIZE,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Build a more memory-efficient model\n",
    "def create_lightweight_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(16, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "        MaxPooling2D(2, 2),\n",
    "\n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "\n",
    "        Flatten(),\n",
    "\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_lightweight_model()\n",
    "model.summary()\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.00001)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=len(test_generator),\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(test_generator)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Get true labels\n",
    "y_true = []\n",
    "for i in range(len(test_generator)):\n",
    "    _, labels = test_generator[i]\n",
    "    y_true.extend(np.argmax(labels, axis=1))\n",
    "y_true = np.array(y_true)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred_classes, target_names=class_names))\n",
    "\n",
    "# Confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, classes):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=classes, yticklabels=classes)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(y_true, y_pred_classes, class_names)\n",
    "\n",
    "# Plot training history\n",
    "def plot_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)\n",
    "\n",
    "# Save actual vs predicted labels (sample 100 for memory)\n",
    "def save_sample_results(generator, model, classes, filename='actual_vs_predicted_sample.csv'):\n",
    "    results = []\n",
    "    sample_size = min(100, len(generator) * generator.batch_size)\n",
    "    indices = np.random.choice(range(len(generator) * generator.batch_size), sample_size, replace=False)\n",
    "\n",
    "    for idx in indices:\n",
    "        batch_idx = idx // generator.batch_size\n",
    "        item_idx = idx % generator.batch_size\n",
    "\n",
    "        X, y = generator[batch_idx]\n",
    "        if item_idx >= len(X):\n",
    "            continue\n",
    "\n",
    "        img = X[item_idx]\n",
    "        true_label = classes[np.argmax(y[item_idx])]\n",
    "        pred = model.predict(np.expand_dims(img, axis=0))\n",
    "        pred_label = classes[np.argmax(pred)]\n",
    "\n",
    "        results.append({\n",
    "            'Image Index': idx,\n",
    "            'Actual Label': true_label,\n",
    "            'Predicted Label': pred_label,\n",
    "            'Correct': true_label == pred_label\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Saved sample results to {filename}\")\n",
    "    return df\n",
    "\n",
    "results_df = save_sample_results(test_generator, model, class_names)\n",
    "\n",
    "# Visualize sample predictions\n",
    "def visualize_sample_predictions(generator, model, classes, num_samples=8):\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    sample_indices = np.random.choice(range(len(generator)), num_samples)\n",
    "\n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        X, y = generator[idx]\n",
    "        img_idx = np.random.randint(0, len(X))\n",
    "        img = X[img_idx]\n",
    "        true_label = classes[np.argmax(y[img_idx])]\n",
    "        pred = model.predict(np.expand_dims(img, axis=0))\n",
    "        pred_label = classes[np.argmax(pred)]\n",
    "\n",
    "        plt.subplot(3, 3, i+1)\n",
    "        plt.imshow(img)\n",
    "        title_color = 'green' if true_label == pred_label else 'red'\n",
    "        plt.title(f\"True: {true_label}\\nPred: {pred_label}\", color=title_color)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_sample_predictions(test_generator, model, class_names)\n",
    "\n",
    "# Save the model\n",
    "model.save('brain_tumor_classifier_light.h5')\n",
    "print(\"Model saved as brain_tumor_classifier_light.h5\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
